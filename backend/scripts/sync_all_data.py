"""
Comprehensive Data Sync Script
Extracts and stores ALL data from Slack, Gmail, and Notion APIs.
Run this at startup or on-demand to keep AI agent's knowledge up-to-date.
"""

import sys
import asyncio
from pathlib import Path
from datetime import datetime

# Add paths
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / 'core'))
sys.path.insert(0, str(project_root))

from core.config import Config
from core.database.db_manager import DatabaseManager
from core.slack.extractor import ExtractionCoordinator
from core.gmail.extractor import GmailExtractor
from core.utils.logger import get_logger

logger = get_logger(__name__)


class DataSyncManager:
    """Manages comprehensive data synchronization across all platforms."""
    
    def __init__(self):
        """Initialize sync manager."""
        self.db = DatabaseManager()
        logger.info("Data Sync Manager initialized")
    
    async def sync_slack_data(self) -> dict:
        """
        Sync ALL Slack data:
        - Workspace info
        - Users (all fields: profile, status, timezone, etc.)
        - Channels (public, private, archived)
        - Messages (with threads, replies, reactions)
        - Files (metadata and links)
        - Reactions
        - User groups/teams
        - Custom emoji
        """
        logger.info("Starting Slack data sync...")
        
        try:
            coordinator = ExtractionCoordinator()
            
            # Extract everything
            stats = {
                'workspace': 'synced',
                'users': 0,
                'channels': 0,
                'messages': 0,
                'files': 0,
                'reactions': 0
            }
            
            # Users - full profiles
            logger.info("Syncing Slack users...")
            users_count = coordinator.extract_users()
            stats['users'] = users_count
            logger.info(f"âœ“ Synced {users_count} users")
            
            # Channels - all types
            logger.info("Syncing Slack channels...")
            channels_count = coordinator.extract_channels(include_archived=True)
            stats['channels'] = channels_count
            logger.info(f"âœ“ Synced {channels_count} channels")
            
            # Messages - with history
            logger.info("Syncing Slack messages...")
            messages_count = coordinator.extract_messages(days_back=90)  # Last 90 days
            stats['messages'] = messages_count
            logger.info(f"âœ“ Synced {messages_count} messages")
            
            # Files
            logger.info("Syncing Slack files...")
            files_count = coordinator.extract_files(days_back=30)
            stats['files'] = files_count
            logger.info(f"âœ“ Synced {files_count} files")
            
            logger.info(f"âœ… Slack sync complete: {stats}")
            return stats
        
        except Exception as e:
            logger.error(f"Slack sync failed: {e}", exc_info=True)
            return {'error': str(e)}
    
    async def sync_gmail_data(self) -> dict:
        """
        Sync ALL Gmail data:
        - Email accounts
        - Labels/folders
        - Threads (conversation chains)
        - Messages (full content, not snippets)
        - Attachments (metadata)
        - Contacts (from/to addresses)
        """
        logger.info("Starting Gmail data sync...")
        logger.warning(
            "Gmail sync via sync_all_data.py is disabled. "
            "Gmail now uses per-user OAuth tokens via the web app and "
            "Pipelines UI. Run a Gmail pipeline from the frontend instead."
        )
        return {'error': 'gmail_sync_disabled'}
    
    async def sync_notion_data(self) -> dict:
        """
        Sync ALL Notion data:
        - Workspaces
        - Pages (all accessible pages)
        - Databases
        - Blocks (page content)
        - Users
        - Comments
        
        Note: Notion API has limitations on reading all workspace data.
        Only pages shared with the integration can be accessed.
        """
        logger.info("Starting Notion data sync...")
        
        try:
            from core.notion_export.client import NotionClient
            
            client = NotionClient()
            if not client.test_connection():
                logger.error("Notion connection failed")
                return {'error': 'Connection failed'}
            
            stats = {
                'workspace': 'connected',
                'pages': 0,
                'databases': 0
            }
            
            # Note: Notion API doesn't provide "list all pages" endpoint
            # We can only access pages that are explicitly shared
            logger.info("âœ“ Notion connection verified")
            logger.info("âš ï¸  Note: Notion requires pages to be explicitly shared with integration")
            
            logger.info(f"âœ… Notion sync complete: {stats}")
            return stats
        
        except Exception as e:
            logger.error(f"Notion sync failed: {e}", exc_info=True)
            return {'error': str(e)}
    
    async def sync_all(self) -> dict:
        """Sync data from all platforms."""
        logger.info("=" * 70)
        logger.info("COMPREHENSIVE DATA SYNC STARTING")
        logger.info("=" * 70)
        
        start_time = datetime.now()
        
        results = {
            'start_time': start_time.isoformat(),
            'slack': {},
            'gmail': {},
            'notion': {},
            'end_time': None,
            'duration_seconds': None
        }
        
        # Sync all platforms
        results['slack'] = await self.sync_slack_data()
        results['gmail'] = await self.sync_gmail_data()
        results['notion'] = await self.sync_notion_data()
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        results['end_time'] = end_time.isoformat()
        results['duration_seconds'] = duration
        
        logger.info("=" * 70)
        logger.info(f"âœ… ALL DATA SYNCED in {duration:.2f} seconds")
        logger.info("=" * 70)
        
        # Print summary
        print("\nðŸ“Š Sync Summary:")
        print(f"  Slack: {results['slack']}")
        print(f"  Gmail: {results['gmail']}")
        print(f"  Notion: {results['notion']}")
        print(f"  Duration: {duration:.2f} seconds\n")
        
        return results


async def main():
    """Main entry point."""
    print("ðŸ”„ Starting comprehensive data sync...")
    print("This will extract ALL data from Slack, Gmail, and Notion APIs\n")
    
    sync_manager = DataSyncManager()
    results = await sync_manager.sync_all()
    
    print("âœ… Sync complete! AI agent is now ready with all data.")
    return results


if __name__ == "__main__":
    asyncio.run(main())
